{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6_K-ZymQOqZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, Dropout, BatchNormalization, MaxPooling2D, Flatten, Input\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Layer\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from keras.preprocessing.image import img_to_array, load_img\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crawl data"
      ],
      "metadata": {
        "id": "qnWQc1MgXqZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "path = \"/content/drive/MyDrive/data/Dataset/\"\n",
        "train, test = \"Train\", \"Test\"\n",
        "train_path = path + train\n",
        "test_path = path + test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVFOnIR6Qcpw",
        "outputId": "3f0bbb05-8013-4186-e36a-9814d0c6077d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(train_path,\n",
        "                                               target_size = (224, 224),\n",
        "                                               batch_size = 32,\n",
        "                                               class_mode = 'categorical')\n",
        "test_data = test_datagen.flow_from_directory(test_path,\n",
        "                                             target_size = (224, 224),\n",
        "                                             batch_size = 32,\n",
        "                                             class_mode = 'categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYG-c_uaQk57",
        "outputId": "ebfa944b-6acf-4202-9045-7c041983a8dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 416 images belonging to 2 classes.\n",
            "Found 134 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model and Training"
      ],
      "metadata": {
        "id": "jdbZRKG1Xujv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class feature_extractor(Layer):\n",
        "  def __init__(self, input_shape):\n",
        "    super(feature_extractor, self).__init__()\n",
        "    self.conv1 = Conv2D(filters = 16, kernel_size = 3, strides = 1, padding = 'valid', activation = 'relu', input_shape = input_shape)\n",
        "    self.maxpool1 = MaxPooling2D(pool_size = 2)\n",
        "    self.batchnorm1 = BatchNormalization()\n",
        "\n",
        "    self.conv2 = Conv2D(filters = 32, kernel_size = 3, strides = 1, padding = 'valid', activation = 'relu')\n",
        "    self.maxpool2 = MaxPooling2D(pool_size = 2)\n",
        "    self.batchnorm2 = BatchNormalization()\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.maxpool1(x)\n",
        "    x = self.batchnorm1(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.maxpool2(x)\n",
        "    x = self.batchnorm2(x)\n",
        "    return x\n",
        "\n",
        "class my_model(Model):\n",
        "  def __init__(self):\n",
        "    super(my_model, self).__init__()\n",
        "    self.extractor = feature_extractor(input_shape = (224, 224, 3))\n",
        "    self.flatten = Flatten()\n",
        "    self.fc2 = Dense(128, activation = 'relu')\n",
        "    self.batchnorm = BatchNormalization()\n",
        "    self.fc3 = Dense(2, activation = 'softmax')\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.extractor(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.batchnorm(x)\n",
        "    x = self.fc3(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "zpWPB-OWQlJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = my_model()\n",
        "model.build((None, 224, 224, 3))\n",
        "model.summary()\n",
        "model.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics = 'accuracy')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkUM8hIxUI7R",
        "outputId": "1092bb35-dafb-4060-97e0-0d285cc41056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " feature_extractor_12 (feat  multiple                  5280      \n",
            " ure_extractor)                                                  \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        multiple                  0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            multiple                  11944064  \n",
            "                                                                 \n",
            " batch_normalization_36 (Ba  multiple                  512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_21 (Dense)            multiple                  258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11950114 (45.59 MB)\n",
            "Trainable params: 11949762 (45.58 MB)\n",
            "Non-trainable params: 352 (1.38 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callback"
      ],
      "metadata": {
        "id": "890mSooFcQSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import Callback, CSVLogger, EarlyStopping\n",
        "\n",
        "class LossCallback(Callback):\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    print(\"\\n Epoch {}, loss is {}\".format(epoch, logs['loss']))\n",
        "\n",
        "  def on_batch_end(self, batch, logs):\n",
        "     print(\"\\n Batch {}, loss is {}\".format(batch, logs))"
      ],
      "metadata": {
        "id": "ZcYIQiiKcTNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CSVLogger"
      ],
      "metadata": {
        "id": "16x1OL_shOu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_callback = CSVLogger(\n",
        "    filename = 'logs.csv',\n",
        "    separator = ',',\n",
        "    append = False\n",
        ")"
      ],
      "metadata": {
        "id": "lTwDK2sTgEw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Early Stopping"
      ],
      "metadata": {
        "id": "ivxl3EOChXuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopping = EarlyStopping(\n",
        "    monitor = 'val_loss',\n",
        "    min_delta = 0.1,\n",
        "    patience = 3\n",
        ")"
      ],
      "metadata": {
        "id": "xgxKFBQUhbDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data, batch_size = 32, epochs = 3, verbose = 1, validation_data = test_data, callbacks = [csv_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Zgts8L9WgF3",
        "outputId": "bb83bfb6-24e4-4b10-9fa9-b045e960d913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "13/13 [==============================] - 30s 2s/step - loss: 0.0129 - accuracy: 0.9976 - val_loss: 2.0204 - val_accuracy: 0.5000\n",
            "Epoch 2/3\n",
            "13/13 [==============================] - 30s 2s/step - loss: 0.0212 - accuracy: 0.9952 - val_loss: 1.5320 - val_accuracy: 0.5672\n",
            "Epoch 3/3\n",
            "13/13 [==============================] - 30s 2s/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 2.2586 - val_accuracy: 0.4478\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fe551e9e8c0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}